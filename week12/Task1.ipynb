{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UavNr56CYduI",
        "outputId": "beeba951-3c30-4689-e92f-bc684df7c6ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (3.6.0)\n",
            "Requirement already satisfied: keras-preprocessing in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (1.1.2)\n",
            "Requirement already satisfied: tensorflow in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (2.18.0)\n",
            "Requirement already satisfied: spacy in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (3.8.4)\n",
            "Requirement already satisfied: pydantic in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (2.8.2)\n",
            "Requirement already satisfied: absl-py in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (13.1.0)\n",
            "Requirement already satisfied: namex in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras) (24.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from keras-preprocessing) (1.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (5.29.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (2.32.2)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (69.5.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from pydantic) (2.20.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from rich->keras) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from rich->keras) (2.15.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/envs/cvenv/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install keras keras-preprocessing tensorflow spacy pydantic\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rapdbERIY1Lc"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LeEXVrhQYxb-"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from random import randint\n",
        "from pickle import dump, load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WinVrL_HZC0w",
        "outputId": "320c889a-f9ba-458e-d05d-078063537af3"
      },
      "outputs": [],
      "source": [
        "# Read file\n",
        "def read_file(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "# Tokenize and clean text\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
        "nlp.max_length = 1198623\n",
        "\n",
        "def separate_punc(text):\n",
        "    return [token.text.lower() for token in nlp(text) if token.text.isalpha()]\n",
        "\n",
        "text = read_file('moby_dick_four_chapters.txt')\n",
        "tokens = separate_punc(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "M9yWgfkTZPQG"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "seq_len = 25\n",
        "sequences = [\n",
        "    tokens[i-seq_len:i]\n",
        "    for i in range(seq_len, len(tokens))\n",
        "]\n",
        "\n",
        "# Tokenize sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "encoded_sequences = np.array(tokenizer.texts_to_sequences(sequences))\n",
        "\n",
        "# Prepare input and target\n",
        "X, y = encoded_sequences[:, :-1], encoded_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_counts) + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "ms1IvjTSZqgD",
        "outputId": "41726c96-2013-4f51-8d53-569ecc93799a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build the model\n",
        "def create_model(vocab_size, seq_len):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 25, input_length=seq_len),\n",
        "        LSTM(150, return_sequences=True),\n",
        "        LSTM(150),\n",
        "        Dense(150, activation='relu'),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model(len(tokenizer.word_counts) + 1, seq_len)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "pguNMjRNZ2zL",
        "outputId": "90b6cb65-b546-464e-9e91-2e66064fca5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 199ms/step - accuracy: 0.1033 - loss: 4.5954\n",
            "Epoch 2/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 240ms/step - accuracy: 0.1060 - loss: 4.5453\n",
            "Epoch 3/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 187ms/step - accuracy: 0.1041 - loss: 4.5137\n",
            "Epoch 4/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 230ms/step - accuracy: 0.1025 - loss: 4.4955\n",
            "Epoch 5/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 218ms/step - accuracy: 0.1075 - loss: 4.4655\n",
            "Epoch 6/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 168ms/step - accuracy: 0.1079 - loss: 4.4364\n",
            "Epoch 7/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 247ms/step - accuracy: 0.1049 - loss: 4.4192\n",
            "Epoch 8/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 179ms/step - accuracy: 0.1075 - loss: 4.3967\n",
            "Epoch 9/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 242ms/step - accuracy: 0.1088 - loss: 4.3900\n",
            "Epoch 10/10\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 244ms/step - accuracy: 0.1100 - loss: 4.3665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, y, batch_size=128, epochs= 10, verbose=1)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save('model1.h5')\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.0684 - loss: 5.7085\n",
            "Epoch 2/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.0713 - loss: 5.5436\n",
            "Epoch 3/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 83ms/step - accuracy: 0.0786 - loss: 5.4406\n",
            "Epoch 4/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.0829 - loss: 5.3230\n",
            "Epoch 5/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 69ms/step - accuracy: 0.0795 - loss: 5.2265\n",
            "Epoch 6/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 69ms/step - accuracy: 0.0884 - loss: 5.1216\n",
            "Epoch 7/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 97ms/step - accuracy: 0.0921 - loss: 5.0208\n",
            "Epoch 8/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 73ms/step - accuracy: 0.0921 - loss: 4.8991\n",
            "Epoch 9/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 67ms/step - accuracy: 0.0911 - loss: 4.8307\n",
            "Epoch 10/10\n",
            "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 118ms/step - accuracy: 0.0958 - loss: 4.7563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, y, batch_size=16, epochs= 10, verbose=1)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save('model2.h5')\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1 Results: Loss = 4.306352138519287, Accuracy = 0.11404453963041306\n",
            "Model 2 Results: Loss = 4.615689277648926, Accuracy = 0.10326867550611496\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the models\n",
        "model1 = load_model('model1.h5')\n",
        "model2 = load_model('model2.h5')\n",
        "\n",
        "# Example: Evaluate on test data (X_test, y_test)\n",
        "model1_results = model1.evaluate(X, y, verbose=0)\n",
        "model2_results = model2.evaluate(X, y, verbose=0)\n",
        "\n",
        "print(f\"Model 1 Results: Loss = {model1_results[0]}, Accuracy = {model1_results[1]}\")\n",
        "print(f\"Model 2 Results: Loss = {model2_results[0]}, Accuracy = {model2_results[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_PJj-2e5Z9V-"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    \"\"\"\n",
        "    INPUTS:\n",
        "    model : Trained model\n",
        "    tokenizer : Tokenizer fit on text data\n",
        "    seq_len : Length of training sequences\n",
        "    seed_text : Initial text to start generating\n",
        "    num_gen_words : Number of words to generate\n",
        "    \"\"\"\n",
        "    output_text = []  # Final output words\n",
        "    input_text = seed_text  # Initial seed text\n",
        "\n",
        "    for _ in range(num_gen_words):\n",
        "        # Encode the input text\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "\n",
        "        # Pad the encoded sequence to match the sequence length\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "\n",
        "        # Predict probabilities and find the index of the word with the highest probability\n",
        "        pred_word_encoded = model.predict(pad_encoded, verbose=0)\n",
        "        pred_word_ind = np.argmax(pred_word_encoded, axis=1)[0]\n",
        "\n",
        "        # Map the predicted index to the corresponding word\n",
        "        pred_word = tokenizer.index_word.get(pred_word_ind, '')\n",
        "\n",
        "        # Update the input text with the predicted word and append to output\n",
        "        input_text += ' ' + pred_word\n",
        "        output_text.append(pred_word)\n",
        "\n",
        "    # Return the generated words as a single string\n",
        "    return ' '.join(output_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed Text: ten inches thick in a hard asphaltic weary for me when i struck my foot against the flinty projections because from hard remorseless service the\n",
            "\n",
            "Generated Text: bed of the little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little\n"
          ]
        }
      ],
      "source": [
        "# Generate and explore text\n",
        "random_seed = randint(0, len(sequences))\n",
        "seed_text = ' '.join(sequences[random_seed])\n",
        "print(f\"Seed Text: {seed_text}\\n\")\n",
        "generated_text = generate_text(model, tokenizer, seq_len, seed_text, num_gen_words=50)\n",
        "print(f\"Generated Text: {generated_text}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
